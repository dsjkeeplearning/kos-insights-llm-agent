services:
  llm-agent:
    container_name: insights-llm-agent
    image: llm-agent:latest
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    env_file:
      - .env
    restart: unless-stopped
    command: python app.py
